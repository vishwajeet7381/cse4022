{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, RegexpStemmer, SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/1661/1661-0.txt\"\n",
    "txt = request.urlopen(url).read().decode(\"utf8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', ',', 'by', 'Arthur', 'Conan', 'Doyle', 'This', 'eBook', 'is', 'for', 'the']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(txt)\n",
    "print(tokens[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacti\n",
      "happi\n"
     ]
    }
   ],
   "source": [
    "porter1 = PorterStemmer()\n",
    "print(porter1.stem(\"cacti\"))\n",
    "print(porter1.stem(\"happiness\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cact\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "porter2 = LancasterStemmer()\n",
    "print(porter2.stem(\"cacti\"))\n",
    "print(porter2.stem(\"happiness\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n"
     ]
    }
   ],
   "source": [
    "porter3 = RegexpStemmer(\"ing\")\n",
    "print(porter3.stem(\"singing\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detest\n",
      "avoir\n"
     ]
    }
   ],
   "source": [
    "porter4 = SnowballStemmer(\"french\")\n",
    "print(porter4.stem(\"detester\"))\n",
    "print(porter4.stem(\"avoir\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer: \n",
      "Lorem->lorem\n",
      "Ipsum->ipsum\n",
      "is->is\n",
      "simply->simpli\n",
      "dummy->dummi\n",
      "text->text\n",
      "of->of\n",
      "the->the\n",
      "printing->print\n",
      "and->and\n",
      "typesetting->typeset\n",
      "industry.->industry.\n",
      "Lorem->lorem\n",
      "Ipsum->ipsum\n",
      "has->ha\n",
      "been->been\n",
      "the->the\n",
      "industry's->industry'\n",
      "standard->standard\n",
      "dummy->dummi\n",
      "text->text\n",
      "ever->ever\n",
      "since->sinc\n",
      "the->the\n",
      "1500s,->1500s,\n",
      "when->when\n",
      "an->an\n",
      "unknown->unknown\n",
      "printer->printer\n",
      "took->took\n",
      "a->a\n",
      "galley->galley\n",
      "of->of\n",
      "type->type\n",
      "and->and\n",
      "scrambled->scrambl\n",
      "it->it\n",
      "to->to\n",
      "make->make\n",
      "a->a\n",
      "type->type\n",
      "specimen->specimen\n",
      "book.->book.\n",
      "It->it\n",
      "has->ha\n",
      "survived->surviv\n",
      "not->not\n",
      "only->onli\n",
      "five->five\n",
      "centuries,->centuries,\n",
      "but->but\n",
      "also->also\n",
      "the->the\n",
      "leap->leap\n",
      "into->into\n",
      "electronic->electron\n",
      "typesetting,->typesetting,\n",
      "remaining->remain\n",
      "essentially->essenti\n",
      "unchanged.->unchanged.\n",
      "It->it\n",
      "was->wa\n",
      "popularised->popularis\n",
      "in->in\n",
      "the->the\n",
      "1960s->1960\n",
      "with->with\n",
      "the->the\n",
      "release->releas\n",
      "of->of\n",
      "Letraset->letraset\n",
      "sheets->sheet\n",
      "containing->contain\n",
      "Lorem->lorem\n",
      "Ipsum->ipsum\n",
      "passages,->passages,\n",
      "and->and\n",
      "more->more\n",
      "recently->recent\n",
      "with->with\n",
      "desktop->desktop\n",
      "publishing->publish\n",
      "software->softwar\n",
      "like->like\n",
      "Aldus->aldu\n",
      "PageMaker->pagemak\n",
      "including->includ\n",
      "versions->version\n",
      "of->of\n",
      "Lorem->lorem\n",
      "Ipsum.->ipsum.\n"
     ]
    }
   ],
   "source": [
    "some_txt = (\n",
    "    \"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem\"\n",
    "    \" Ipsum has been the industry's standard dummy text ever since the 1500s, when an\"\n",
    "    \" unknown printer took a galley of type and scrambled it to make a type specimen\"\n",
    "    \" book. It has survived not only five centuries, but also the leap into electronic\"\n",
    "    \" typesetting, remaining essentially unchanged. It was popularised in the 1960s\"\n",
    "    \" with the release of Letraset sheets containing Lorem Ipsum passages, and more\"\n",
    "    \" recently with desktop publishing software like Aldus PageMaker including versions\"\n",
    "    \" of Lorem Ipsum.\"\n",
    ")\n",
    "some_txt_stemmers = [porter1.stem(word) for word in some_txt.split()]\n",
    "print(\"Porter Stemmer: \")\n",
    "for word, stem in zip(some_txt.split(), some_txt_stemmers):\n",
    "    print(word, stem, sep=\"->\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancaster Stemmer: \n",
      "Lorem->lorem\n",
      "Ipsum->ips\n",
      "is->is\n",
      "simply->simply\n",
      "dummy->dummy\n",
      "text->text\n",
      "of->of\n",
      "the->the\n",
      "printing->print\n",
      "and->and\n",
      "typesetting->typeset\n",
      "industry.->industry.\n",
      "Lorem->lorem\n",
      "Ipsum->ips\n",
      "has->has\n",
      "been->been\n",
      "the->the\n",
      "industry's->industry's\n",
      "standard->standard\n",
      "dummy->dummy\n",
      "text->text\n",
      "ever->ev\n",
      "since->sint\n",
      "the->the\n",
      "1500s,->1500s,\n",
      "when->when\n",
      "an->an\n",
      "unknown->unknown\n",
      "printer->print\n",
      "took->took\n",
      "a->a\n",
      "galley->galley\n",
      "of->of\n",
      "type->typ\n",
      "and->and\n",
      "scrambled->scrambled\n",
      "it->it\n",
      "to->to\n",
      "make->mak\n",
      "a->a\n",
      "type->typ\n",
      "specimen->specim\n",
      "book.->book.\n",
      "It->it\n",
      "has->has\n",
      "survived->surv\n",
      "not->not\n",
      "only->on\n",
      "five->fiv\n",
      "centuries,->centuries,\n",
      "but->but\n",
      "also->also\n",
      "the->the\n",
      "leap->leap\n",
      "into->into\n",
      "electronic->electron\n",
      "typesetting,->typesetting,\n",
      "remaining->remain\n",
      "essentially->ess\n",
      "unchanged.->unchanged.\n",
      "It->it\n",
      "was->was\n",
      "popularised->popul\n",
      "in->in\n",
      "the->the\n",
      "1960s->1960s\n",
      "with->with\n",
      "the->the\n",
      "release->releas\n",
      "of->of\n",
      "Letraset->letraset\n",
      "sheets->sheet\n",
      "containing->contain\n",
      "Lorem->lorem\n",
      "Ipsum->ips\n",
      "passages,->passages,\n",
      "and->and\n",
      "more->mor\n",
      "recently->rec\n",
      "with->with\n",
      "desktop->desktop\n",
      "publishing->publ\n",
      "software->softw\n",
      "like->lik\n",
      "Aldus->ald\n",
      "PageMaker->pagemak\n",
      "including->includ\n",
      "versions->vert\n",
      "of->of\n",
      "Lorem->lorem\n",
      "Ipsum.->ipsum.\n"
     ]
    }
   ],
   "source": [
    "some_txt = (\n",
    "    \"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem\"\n",
    "    \" Ipsum has been the industry's standard dummy text ever since the 1500s, when an\"\n",
    "    \" unknown printer took a galley of type and scrambled it to make a type specimen\"\n",
    "    \" book. It has survived not only five centuries, but also the leap into electronic\"\n",
    "    \" typesetting, remaining essentially unchanged. It was popularised in the 1960s\"\n",
    "    \" with the release of Letraset sheets containing Lorem Ipsum passages, and more\"\n",
    "    \" recently with desktop publishing software like Aldus PageMaker including versions\"\n",
    "    \" of Lorem Ipsum.\"\n",
    ")\n",
    "some_txt_stemmers = [porter2.stem(word) for word in some_txt.split()]\n",
    "print(\"Lancaster Stemmer: \")\n",
    "for word, stem in zip(some_txt.split(), some_txt_stemmers):\n",
    "    print(word, stem, sep=\"->\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse4022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d231c6ae6a395e72cdb34aad0d94e0c7194206fc17f69c6789bfd920de672766"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
